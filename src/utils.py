# utils.py
import logging
import pandas as pd
import os
from src.config import CSV_MAIN, PROCESSED_DIR
from pathlib import Path
from datetime import datetime
from src.config import SENT_LINKS_PATH, SENT_IDS_PATH

def setup_logger():
    logging.basicConfig(
        format="%(asctime)s - %(levelname)s - %(message)s",
        level=logging.INFO
    )

def load_today_rows() -> pd.DataFrame:
    csv_path = get_today_processed_csv()
    if not os.path.exists(csv_path):
        print(f"‚ùå CSV –Ω–µ –Ω–∞–π–¥–µ–Ω: {csv_path}")
        return pd.DataFrame()
    try:
        df = pd.read_csv(csv_path)
        today_str = datetime.now().strftime("%Y-%m-%d")
        filtered_df = df[df["published_date_dt"] == today_str]
        
        print(f"üîé –ù–∞–π–¥–µ–Ω–æ {len(filtered_df)} –≤–∞–∫–∞–Ω—Å–∏–π –∑–∞ {today_str}")
        return filtered_df

    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è CSV: {e}")
        return pd.DataFrame()
    

def append_sent_links(links: list, path: str = SENT_LINKS_PATH):
    os.makedirs(os.path.dirname(path), exist_ok=True)
    with open(path, "a", encoding="utf-8") as f:
        for link in links:
            f.write(link + "\n")
    
def load_sent_links(path: str = SENT_LINKS_PATH) -> set:
    if not os.path.exists(path):
        return set()
    with open(path, "r", encoding="utf-8") as f:
        return set(line.strip() for line in f)

def load_sent_ids(path: str = SENT_IDS_PATH) -> set:
    if not os.path.exists(path):
        return set()
    with open(path, "r", encoding="utf-8") as f:
        return set(line.strip() for line in f)

def append_sent_ids(ids: list, path: str = SENT_IDS_PATH):
    os.makedirs(os.path.dirname(path), exist_ok=True)
    with open(path, "a", encoding="utf-8") as f:
        for vacancy_id in ids:
            f.write(vacancy_id + "\n")

def extract_vacancy_id(link: str) -> str:
    try:
        return link.split('/vacancy/')[1].split('?')[0]
    except (IndexError, AttributeError):
        return None

def get_today_processed_csv():
    today = datetime.now().strftime("%Y-%m-%d")
    return f"data/processed/vacancies_clean_{today}.csv"

def load_existing_links(csv_path: str) -> set:
    """
    –ó–∞–≥—Ä—É–∂–∞–µ—Ç –≤—Å–µ —Å—Å—ã–ª–∫–∏ –∏–∑ –Ω–∞–∫–æ–ø–∏—Ç–µ–ª—å–Ω–æ–≥–æ CSV –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –º–Ω–æ–∂–µ—Å—Ç–≤–æ –∫–∞–Ω–æ–Ω–∏—á–µ—Å–∫–∏—Ö URL.
    """
    if Path(csv_path).exists():
        df = pd.read_csv(csv_path, usecols=["link"], dtype={"link": str})
        # –ö–∞–Ω–æ–Ω–∏–∑–∏—Ä—É–µ–º –∫–∞–∂–¥—É—é —Å—Å—ã–ª–∫—É –∏ —É–±–∏—Ä–∞–µ–º NaN
        return {
            canonical_link(link)
            for link in df["link"].dropna().unique()
        }
    return set()

def save_to_main_csv(data: list[dict], csv_path: str):
    """
    –î–æ–±–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–µ –∑–∞–ø–∏—Å–∏ –≤ –Ω–∞–∫–æ–ø–∏—Ç–µ–ª—å–Ω—ã–π CSV, —É–±–∏—Ä–∞—è –¥—É–±–ª–∏–∫–∞—Ç—ã –ø–æ –∫–∞–Ω–æ–Ω–∏—á–µ—Å–∫–æ–º—É URL.
    """
    Path(csv_path).parent.mkdir(parents=True, exist_ok=True)
    
    df_new = pd.DataFrame(data)
    # –ö–∞–Ω–æ–Ω–∏–∑–∏—Ä—É–µ–º —Å—Å—ã–ª–∫–∏ –≤ –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö
    df_new["link"] = df_new["link"].apply(canonical_link)

    if Path(csv_path).exists():
        df_old = pd.read_csv(csv_path, dtype={"link": str})
        # –ö–∞–Ω–æ–Ω–∏–∑–∏—Ä—É–µ–º —Å—Ç–∞—Ä—ã–µ —Å—Å—ã–ª–∫–∏
        df_old["link"] = df_old["link"].apply(canonical_link)

        # –û–±—ä–µ–¥–∏–Ω—è–µ–º –∏ —É–¥–∞–ª—è–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã
        df_combined = pd.concat([df_old, df_new], ignore_index=True)
        df_combined = df_combined.drop_duplicates(subset=["link"])
    else:
        df_combined = df_new

    df_combined.to_csv(csv_path, index=False, encoding="utf-8-sig")



def save_raw_data(df: pd.DataFrame, file_path: str):
    """
    –°–æ—Ö—Ä–∞–Ω—è–µ—Ç –µ–∂–µ–¥–Ω–µ–≤–Ω—ã–π –¥–∞–º–ø –≤–∞–∫–∞–Ω—Å–∏–π –≤ –æ—Ç–¥–µ–ª—å–Ω—ã–π CSV.
    """
    Path(file_path).parent.mkdir(parents=True, exist_ok=True)
    df.to_csv(file_path, index=False, encoding="utf-8-sig")
    logging.info(f"[INFO] Raw data saved to: {file_path}")


def clean_text_safe(text):
    if not isinstance(text, str):
        return ""
    return text.replace("\xa0", " ").strip()

def determine_mode() -> str:
    if not os.path.exists(CSV_MAIN):
        return "full"
    try:
        df = pd.read_csv(CSV_MAIN)
        return "full" if df.empty else "daily"
    except Exception:
        return "full"


def save_daily_clean_csv(df: pd.DataFrame):
    os.makedirs(PROCESSED_DIR, exist_ok=True)
    filename = f"vacancies_clean_{datetime.now().strftime('%Y-%m-%d')}.csv"
    full_path = os.path.join(PROCESSED_DIR, filename)
    df.to_csv(full_path, index=False)
    print(f"[INFO] Saved cleaned data to: {full_path}")


def canonical_link(link: str) -> str:
    """
    –û–±—Ä–µ–∑–∞–µ—Ç –≤—Å–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –ø–æ—Å–ª–µ '?' –≤ URL –≤–∞–∫–∞–Ω—Å–∏–∏, –æ—Å—Ç–∞–≤–ª—è—è –±–∞–∑–æ–≤—ã–π –ø—É—Ç—å.
    """
    try:
        return link.split("?", 1)[0]
    except Exception:
        return link

