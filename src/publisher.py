import pandas as pd
import asyncio
import os
import random
import ast
from datetime import datetime
from telegram import Bot
from src.config import TELEGRAM_BOT_TOKEN, CHANNEL_USERNAME, get_today_processed_csv
from src.llm_summary import summarize_description_llm, filter_vacancy_llm

# ‚Äî‚Äî‚Äî –ü—É—Ç—å –¥–æ —Ñ–∞–π–ª–∞ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã—Ö —Å—Å—ã–ª–æ–∫ ‚Äî‚Äî‚Äî
SENT_LINKS_PATH = "data/sent_links.txt"

# ‚Äî‚Äî‚Äî –ó–∞–≥—Ä—É–∑–∫–∞ —Ä–∞–Ω–µ–µ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã—Ö —Å—Å—ã–ª–æ–∫ ‚Äî‚Äî‚Äî
def load_sent_links(path: str = SENT_LINKS_PATH) -> set:
    if not os.path.exists(path):
        return set()
    with open(path, "r", encoding="utf-8") as f:
        return set(line.strip() for line in f)

# ‚Äî‚Äî‚Äî –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –Ω–æ–≤—ã—Ö –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã—Ö —Å—Å—ã–ª–æ–∫ ‚Äî‚Äî‚Äî
def append_sent_links(links: list, path: str = SENT_LINKS_PATH):
    os.makedirs(os.path.dirname(path), exist_ok=True)
    with open(path, "a", encoding="utf-8") as f:
        for link in links:
            f.write(link + "\n")

# ‚Äî‚Äî‚Äî –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω–∞—è –∫–æ–Ω–≤–µ—Ä—Å–∏—è LLM-—Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤ Markdown-–±—É–ª–ª–µ—Ç—ã ‚Äî‚Äî‚Äî
def _to_bullets(x) -> str:
    if isinstance(x, list):
        lines = x
    else:
        try:
            parsed = ast.literal_eval(x)
            lines = parsed if isinstance(parsed, list) else [x]
        except Exception:
            lines = [x]
    bullets = []
    for item in lines:
        s = str(item).strip().strip("'\"")
        if s:
            bullets.append(f"‚Ä¢ {s}")
    return "\n".join(bullets) or "–ù–µ —É–∫–∞–∑–∞–Ω–æ"

# ‚Äî‚Äî‚Äî –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –≤–∞–∫–∞–Ω—Å–∏–∏ –¥–ª—è Telegram ‚Äî‚Äî‚Äî
def format_message(row: pd.Series, summary: dict) -> str:
    title = f"**{row.get('title','---')}**"
    pub_date = f"**{row.get('published_date','---')}**"
    resp = _to_bullets(summary.get('responsibilities', '–ù–µ —É–∫–∞–∑–∞–Ω–æ'))
    reqs = _to_bullets(summary.get('requirements', '–ù–µ —É–∫–∞–∑–∞–Ω–æ'))
    about = str(summary.get('about_company', '–ù–µ —É–∫–∞–∑–∞–Ω–æ')).strip().strip("'\"")

    return f"""
üåê *–ì–æ—Ä–æ–¥:* {row.get('location', '---')}
üìÖ *–î–æ–ª–∂–Ω–æ—Å—Ç—å:* {title}
üíº *–ö–æ–º–ø–∞–Ω–∏—è:* {row.get('company', '---')}
üí∞ *–ó–ü:* {row.get('salary_range') or row.get('salary') or '---'}

üéì *–û–ø—ã—Ç:* {row.get('experience', '---')}
üìÇ *–¢–∏–ø –∑–∞–Ω—è—Ç–æ—Å—Ç–∏:* {row.get('employment_type', '---')}
üìÜ *–ì—Ä–∞—Ñ–∏–∫:* {row.get('schedule', '---')}
üïí *–†–∞–±–æ—á–∏–µ —á–∞—Å—ã:* {row.get('working_hours', '---')}
üè† *–§–æ—Ä–º–∞—Ç —Ä–∞–±–æ—Ç—ã:* {row.get('work_format', '---')}
üìÖ *–î–∞—Ç–∞ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏:* {pub_date}

üßæ *–û–±—è–∑–∞–Ω–Ω–æ—Å—Ç–∏:*
{resp}

üéØ *–¢—Ä–µ–±–æ–≤–∞–Ω–∏—è:*
{reqs}

üè¢ *–û –∫–æ–º–ø–∞–Ω–∏–∏:*
{about}

üîé [–ü–æ–¥—Ä–æ–±–Ω–µ–µ –Ω–∞ hh]({row['link']})
""".strip()

# ‚Äî‚Äî‚Äî –ó–∞–≥—Ä—É–∑–∫–∞ CSV –∏ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ —Å–µ–≥–æ–¥–Ω—è—à–Ω–µ–π –¥–∞—Ç–µ ‚Äî‚Äî‚Äî
def load_today_rows() -> pd.DataFrame:
    csv_path = get_today_processed_csv()
    if not os.path.exists(csv_path):
        print(f"‚ùå CSV –Ω–µ –Ω–∞–π–¥–µ–Ω: {csv_path}")
        return pd.DataFrame()
    try:
        df = pd.read_csv(csv_path)
        today_str = datetime.now().strftime("%Y-%m-%d")
        return df[df["published_date_dt"] == today_str] #change if neceessary
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è CSV: {e}")
        return pd.DataFrame()

# ‚Äî‚Äî‚Äî –û—Å–Ω–æ–≤–Ω–æ–π –ø–∞–π–ø–ª–∞–π–Ω –ø—É–±–ª–∏–∫–∞—Ü–∏–∏ –≤–∞–∫–∞–Ω—Å–∏–π ‚Äî‚Äî‚Äî
async def main():
    df = load_today_rows()
    if df.empty:
        print("‚ÑπÔ∏è –°–µ–≥–æ–¥–Ω—è –Ω–µ—Ç –Ω–æ–≤—ã—Ö –≤–∞–∫–∞–Ω—Å–∏–π.")
        return

    sent_links = load_sent_links()
    df = df[~df["link"].isin(sent_links)]
    if df.empty:
        print("‚ÑπÔ∏è –í—Å–µ –≤–∞–∫–∞–Ω—Å–∏–∏ —É–∂–µ –±—ã–ª–∏ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω—ã —Ä–∞–Ω–µ–µ.")
        return

    # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è —á–µ—Ä–µ–∑ Gemini LLM
    filtered = []
    for i, (_, row) in enumerate(df.iterrows(), 1):
        is_relevant = filter_vacancy_llm(row["title"], row["description"])
        print(f"[Gemini Filter] {row['title']} ‚Üí {'‚úÖ' if is_relevant else '‚ùå'}")
        if is_relevant:
            filtered.append(row)
        await asyncio.sleep(4.5)  # –ª–∏–º–∏—Ç 15 rpm

    if not filtered:
        print("‚ùå –ù–µ—Ç —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –≤–∞–∫–∞–Ω—Å–∏–π –ø–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏.")
        return

    df_filtered = pd.DataFrame(filtered)
    bot = Bot(token=TELEGRAM_BOT_TOKEN)

    for i, (_, row) in enumerate(df_filtered.iterrows(), 1):
        summary = summarize_description_llm(row["description"])
        text = format_message(row, summary)
        await bot.send_message(chat_id=CHANNEL_USERNAME, text=text, parse_mode="Markdown")
        print(f"‚úÖ [{i}/{len(df_filtered)}] –í–∞–∫–∞–Ω—Å–∏—è –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–∞.")
        if i < len(df_filtered):
            delay = random.uniform(3, 10)
            print(f"‚è±Ô∏è –ó–∞–¥–µ—Ä–∂–∫–∞ –ø–µ—Ä–µ–¥ —Å–ª–µ–¥—É—é—â–µ–π: {delay:.2f} —Å–µ–∫.")
            await asyncio.sleep(delay)

    append_sent_links(df_filtered["link"].tolist())
    print(f"\nüì¨ –í—Å–µ–≥–æ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ: {len(df_filtered)} –≤–∞–∫–∞–Ω—Å–∏–π.")

def run_publisher():
    return main()
